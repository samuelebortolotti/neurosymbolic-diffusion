{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from torch.nn.functional import softmax\n",
    "from sklearn.calibration import calibration_curve\n",
    "import sys\n",
    "sys.argv = ['']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ece(probs, labels, n_bins=15):\n",
    "    \"\"\"Expected Calibration Error\"\"\"\n",
    "    confidences = probs.max(1)\n",
    "    predictions = probs.argmax(1)\n",
    "    accuracies = predictions == labels\n",
    "\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    ece = torch.zeros(1, device=probs.device)\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        mask = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i + 1])\n",
    "        if mask.any():\n",
    "            acc = accuracies[mask].float().mean()\n",
    "            conf = confidences[mask].mean()\n",
    "            ece += (conf - acc).abs() * mask.float().mean()\n",
    "\n",
    "    return ece.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(y_true, y_pred, labels, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.colorbar(cax)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='left')\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    # Annotate each cell with its value\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i, j]), va='center', ha='center', color='white' if cm[i, j] > cm.max()/2 else 'black')\n",
    "\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_f1(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expressive.util import get_device\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from expressive.experiments.mnist_op.absorbing_mnist import (\n",
    "    MNISTAddProblem,\n",
    "    create_mnistadd,\n",
    "    vector_to_base10,\n",
    ")\n",
    "from expressive.args import MNISTAbsorbingArguments\n",
    "from expressive.experiments.mnist_op.data import (\n",
    "    create_nary_multidigit_operation,\n",
    "    get_mnist_op_dataloaders,\n",
    ")\n",
    "import math\n",
    "\n",
    "from expressive.methods.logger import (\n",
    "    TestLog,\n",
    "    TrainingLog,\n",
    "    TrainLogger,\n",
    "    TestLogger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    val_loader: DataLoader,\n",
    "    test_logger: TestLog,\n",
    "    model: MNISTAddProblem,\n",
    "    device: torch.device,\n",
    "    args,\n",
    "):\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        mn_digits, label_digits, label = (\n",
    "            batch[: 2 * args.N],\n",
    "            batch[2 * args.N : -1],\n",
    "            batch[-1],\n",
    "        )\n",
    "        x = torch.cat(mn_digits, dim=1)\n",
    "        model.evaluate(\n",
    "            x.to(device),\n",
    "            vector_to_base10(label.to(device), args.N + 1),\n",
    "            torch.stack(label_digits, dim=-1).to(device),\n",
    "            test_logger.log,\n",
    "        )\n",
    "        if args.DEBUG:\n",
    "            break\n",
    "    test_logger.push(len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_concepts = []\n",
    "    all_concept_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, concepts, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            concepts = concepts.to(device)\n",
    "\n",
    "            preds, concept_preds = model(x)\n",
    "            y_pred = preds.argmax(dim=1)\n",
    "\n",
    "            all_preds.append(y_pred.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "\n",
    "            c_preds = concept_preds.argmax(dim=-1)\n",
    "            all_concepts.append(c_preds.cpu())\n",
    "            all_concept_labels.append(concepts.cpu())\n",
    "\n",
    "    y_true = torch.cat(all_labels)\n",
    "    y_pred = torch.cat(all_preds)\n",
    "\n",
    "    c_true = torch.cat(all_concept_labels).view(-1)\n",
    "    c_pred = torch.cat(all_concepts).view(-1)\n",
    "\n",
    "    return y_true.numpy(), y_pred.numpy(), c_true.numpy(), c_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficient-vortex-1</strong> at: <a href='https://wandb.ai/samu32/neurosymbolic-diffusion/runs/0vcxjti5' target=\"_blank\">https://wandb.ai/samu32/neurosymbolic-diffusion/runs/0vcxjti5</a><br> View project at: <a href='https://wandb.ai/samu32/neurosymbolic-diffusion' target=\"_blank\">https://wandb.ai/samu32/neurosymbolic-diffusion</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250722_142208-0vcxjti5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/cimec-storage6/users/samuele.bortolotti/neurosymbolic-diffusion/wandb/run-20250722_142222-pz5rqy2l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/samu32/neurosymbolic-diffusion/runs/pz5rqy2l' target=\"_blank\">twilight-donkey-2</a></strong> to <a href='https://wandb.ai/samu32/neurosymbolic-diffusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/samu32/neurosymbolic-diffusion' target=\"_blank\">https://wandb.ai/samu32/neurosymbolic-diffusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/samu32/neurosymbolic-diffusion/runs/pz5rqy2l' target=\"_blank\">https://wandb.ai/samu32/neurosymbolic-diffusion/runs/pz5rqy2l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "args = MNISTAbsorbingArguments(explicit_bool=True).parse_args()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = create_mnistadd(args).to(device)\n",
    "arity = 2\n",
    "digits_per_number = args.N\n",
    "n_operands = arity * digits_per_number\n",
    "\n",
    "bin_op = sum if args.op == \"sum\" else math.prod if args.op == \"product\" else None\n",
    "op = create_nary_multidigit_operation(arity, bin_op)\n",
    "\n",
    "train_size = 60000 if args.test else 50000\n",
    "val_size = 0 if args.test else 10000\n",
    "train_loader, val_loader, test_loader = get_mnist_op_dataloaders(\n",
    "    count_train=int(train_size / n_operands),\n",
    "    count_val=int(val_size / n_operands),\n",
    "    count_test=int(10000 / n_operands),\n",
    "    batch_size=args.batch_size,\n",
    "    n_operands=n_operands,\n",
    "    op=op,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/gv2nx5am/model_12.pth\", map_location=device))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "test_logger = TestLogger(TestLog, args, \"test\")\n",
    "test(test_loader, test_logger, model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
